{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 Code Compiled\n",
    "\n",
    "This file contains all of the Day 1 code re-written and documented to build a simple text summariser with GPT Mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv # loads environment variables from a .env file into your Python environment.\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading environment variable\n",
    "\n",
    "Load an the API key (environment variable) from .env into Python environment and store it as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the environment variables in your `.env` file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# retrieve the environment variable -> string of the API key\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key was found!\n"
     ]
    }
   ],
   "source": [
    "# check the API key is valid\n",
    "if not api_key:\n",
    "    print(\"NO API key was found\")\n",
    "elif not api_key.startswith(\"sk-proj-\"):\n",
    "    print(\"Check you're using the right key\")\n",
    "elif api_key.strip() != api_key:\n",
    "    print(\"The API key may have space of tab characters at the start/end\")\n",
    "else:\n",
    "    print(\"API key was found!\")\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI\n",
    "\n",
    "Make a connection to OpenAI API Service to make a call to GPT (Frontier Model) to ask it questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an OpenAI object\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a quick call to a Froniter Model\n",
    "\n",
    "First, we will make a quick call to gpt-4o-mini, a smaller, more cost-effective version of OpenAI's GPT-4o model, designed to balance performance with affordability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! Welcome! I'm glad you're here. How can I assist you today?\", refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))]\n"
     ]
    }
   ],
   "source": [
    "# input message\n",
    "message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "\n",
    "# response from GPT\n",
    "response = openai.chat.completions.create(model = \"gpt-4o-mini\",\n",
    "                                          messages=[{\n",
    "                                              \"role\":\"user\",\n",
    "                                              \"content\":message\n",
    "                                          }])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome! I'm glad you're here. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# printing response in a cleaner format:\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Summarising webpages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining class to scrape text content off a webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# a class that represents a webpage\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers) # sends https request to get data\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\" # define webpage title\n",
    "        \n",
    "        # finds all <script>, <style>, <img>, and <input> elements inside the <body> tag and removes them\n",
    "        # we only want the main text\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip = True) # define webpage text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'title', 'url']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets explore the text and title attributes stored in this class object Website\n",
    "[attr for attr in dir(Website(\"https://edwarddonner.com\")) if not attr.startswith(\"__\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# lets try out the webpage object that gets the text off a webpage\n",
    "print(Website(\"https://edwarddonner.com\").title)\n",
    "print(Website(\"https://edwarddonner.com\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Prompts:\n",
    "\n",
    "These Frontier models expect two types of instructions:\n",
    "\n",
    "**1. System Prompt:**\n",
    "* Purpose: Provides essential context or instructions to the model about how it should behave as an assistant. E.G: Explain the role of the model.\n",
    "\n",
    "* Example: \"You are a helpful assistant designed to provide clear, concise answers. You can help with coding, answering general knowledge questions, and offering recommendations.\"\n",
    "\n",
    "**2. User Prompt:**\n",
    "\n",
    "* Purpose: What the user inputs—it's the actual conversation or query that the LLM is responding to.\n",
    "\n",
    "* Example: \"User: Can you help me write a Python function that reverses a string?\"\n",
    "\n",
    "The LLM's task is to consider the context of the system prompt while responding to the user’s input in a way that fits the given instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining our user prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that writes a user prompt that asks for summaries of websites\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\n\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "December 21, 2024\n",
      "Welcome, SuperDataScientists!\n",
      "November 13, 2024\n",
      "Mastering AI and LLM Engineering – Resources\n",
      "October 16, 2024\n",
      "From Software Engineer to AI Data Scientist – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# example: user prompt asking for a summary of this webpage\n",
    "print(user_prompt_for(Website(\"https://edwarddonner.com\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages:\n",
    "\n",
    "The OpenAI API expects to receive messages in a particular structure. Many other APIs expect a similar structure:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, let me dust off my math skills... It’s 4. Shocking, I know.\n"
     ]
    }
   ],
   "source": [
    "# example input containing system & user prompts:\n",
    "example_msg = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a snarky assistant\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
    "]\n",
    "\n",
    "# example call to OpenAI with system & user prompts:\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=example_msg)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Building our messsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our system prompt:\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an assistant that analyzes the contents of a website and provides a short summary, ignoring text that might be navigation related. Respond in markdown.'},\n",
       " {'role': 'user',\n",
       "  'content': 'You are looking at a website titled Home - Edward Donner\\n\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nWell, hi there.\\nI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\\nvery\\namateur) and losing myself in\\nHacker News\\n, nodding my head sagely to things I only half understand.\\nI’m the co-founder and CTO of\\nNebula.io\\n. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\\nacquired in 2021\\n.\\nWe work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\\npatented\\nour matching model, and our award-winning platform has happy customers and tons of press coverage.\\nConnect\\nwith me for more!\\nJanuary 23, 2025\\nLLM Workshop – Hands-on with Agents – resources\\nDecember 21, 2024\\nWelcome, SuperDataScientists!\\nNovember 13, 2024\\nMastering AI and LLM Engineering – Resources\\nOctober 16, 2024\\nFrom Software Engineer to AI Data Scientist – resources\\nNavigation\\nHome\\nConnect Four\\nOutsmart\\nAn arena that pits LLMs against each other in a battle of diplomacy and deviousness\\nAbout\\nPosts\\nGet in touch\\ned [at] edwarddonner [dot] com\\nwww.edwarddonner.com\\nFollow me\\nLinkedIn\\nTwitter\\nFacebook\\nSubscribe to newsletter\\nType your email…\\nSubscribe'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_for(Website(\"https://edwarddonner.com\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the Froniter Model\n",
    "\n",
    "We will now define a general function to call the Froniter Model to summarise the content of a webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the OpenAI API\n",
    "def summarise(url):\n",
    "    website = Website(url) # return website object with scraped text\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website) # pass in the user prompt for a particular website\n",
    "    )\n",
    "    return response.choices[0].message.content # output model text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Summary of Edward Donner's Website\\n\\nThis website serves as a personal platform for Ed Donner, who is passionate about coding, experimenting with large language models (LLMs), and electronic music. He is the co-founder and CTO of Nebula.io, a company that leverages AI to enhance talent discovery and engagement. Ed has a background in leading AI startups, including one that was acquired in 2021.\\n\\n## Key Features:\\n- **Connect Four**: A competitive platform where LLMs face off in strategic scenarios.\\n- **Outsmart**: Another interactive arena for LLM competitions.\\n- **About Ed**: Insights into his interests and professional journey.\\n- **Posts**: A collection of resources and articles related to AI and LLMs.\\n\\n## Recent Announcements:\\n- **January 23, 2025**: Resources for the LLM Workshop focused on hands-on experience with agents.\\n- **December 21, 2024**: A warm welcome to a new audience, referred to as SuperDataScientists.\\n- **November 13, 2024**: Availability of resources for mastering AI and LLM engineering.\\n- **October 16, 2024**: Resources released for transitioning from software engineer to AI data scientist. \\n\\nThe site encourages visitors to connect with Ed through various platforms and subscribe to his newsletter for updates.\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example function:\n",
    "summarise(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in Jupyter output, using markdown\n",
    "def display_summary(url):\n",
    "    summary = summarise(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Edward Donner's Website\n",
       "\n",
       "The website serves as a personal space for Ed Donner, a co-founder and CTO of Nebula.io, where he shares his interests in coding, LLMs (large language models), DJing, and electronic music production. Nebula.io focuses on leveraging AI to improve talent discovery and management, boasting a proprietary matching model and an award-winning platform.\n",
       "\n",
       "## Recent Announcements\n",
       "- **January 23, 2025**: LLM Workshop – Hands-on with Agents – resources available.\n",
       "- **December 21, 2024**: Welcome message for SuperDataScientists.\n",
       "- **November 13, 2024**: Resources for \"Mastering AI and LLM Engineering\" shared.\n",
       "- **October 16, 2024**: Resources for transitioning from Software Engineer to AI Data Scientist released.\n",
       "\n",
       "The site encourages connections, inviting visitors to reach out via email and social media."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining this as a single class\n",
    "\n",
    "This makes it simpler to run through the entire process with a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummariseWebpage:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "        self.system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\"\n",
    "\n",
    "    def scrape(self):\n",
    "        \"\"\"\n",
    "          Method to scrape text and title from given url using BeautifulSoup library\n",
    "        \"\"\"\n",
    "        response = requests.get(self.url, headers=self.headers) # sends https request to get data\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\" # define webpage title\n",
    "        \n",
    "        # finds all <script>, <style>, <img>, and <input> elements inside the <body> tag and removes them\n",
    "        # we only want the main text\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip = True) # define webpage text\n",
    "        \n",
    "    def _user_prompt_for(self):\n",
    "        \"\"\"\n",
    "          Method to format user prompt\n",
    "        \"\"\"\n",
    "        user_prompt = f\"You are looking at a website titled {self.title}\"\n",
    "        user_prompt += \"\\n\\nThe contents of this website is as follows; \\\n",
    "    please provide a short summary of this website in markdown. \\\n",
    "    If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "        user_prompt += self.text\n",
    "        return user_prompt\n",
    "    \n",
    "    def _messages_for(self):\n",
    "        \"\"\"\n",
    "          Method to format OpenAI message (contains user & system prompt)\n",
    "        \"\"\"\n",
    "        return [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": self._user_prompt_for()}\n",
    "        ]\n",
    "    \n",
    "    def summarise(self):\n",
    "        \"\"\"\n",
    "          Method that summarises the scraped webpage\n",
    "        \"\"\"\n",
    "        response = openai.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = self._messages_for() # pass in the user prompt for a particular website\n",
    "        )\n",
    "        return response.choices[0].message.content # output model text\n",
    "        \n",
    "    def display_summary(self, text):\n",
    "        \"\"\"\n",
    "          Method to display this nicely in Jupyter output, using markdown\n",
    "        \"\"\"\n",
    "        display(Markdown(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Edward Donner's Website\n",
       "\n",
       "The website is a personal platform of Ed Donner, who is a coder, DJ, and CTO of Nebula.io, a company focused on applying AI in talent discovery and management. He has a background in AI startups and emphasizes his work with large language models (LLMs).\n",
       "\n",
       "## Notable Features\n",
       "- **Professional Background**: Ed is involved in developing AI solutions and has founded an AI startup, untapt, which was acquired in 2021.\n",
       "- **Interests**: Beyond coding, he enjoys DJing and electronic music, albeit at an amateur level.\n",
       "\n",
       "## News and Announcements\n",
       "- **January 23, 2025**: LLM Workshop – Hands-on with Agents – resources provided.\n",
       "- **December 21, 2024**: Welcoming SuperDataScientists to the community.\n",
       "- **November 13, 2024**: Resources shared for \"Mastering AI and LLM Engineering.\"\n",
       "- **October 16, 2024**: Resources for transitioning from Software Engineer to AI Data Scientist have been published. \n",
       "\n",
       "For further engagement, Ed encourages visitors to connect with him through various social channels and to subscribe to his newsletter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# intialise instance of SummariseWebpage object\n",
    "summary = SummariseWebpage(url=\"https://edwarddonner.com\")\n",
    "\n",
    "# scrape webpage and retrieve title & text\n",
    "summary.scrape()\n",
    "\n",
    "# sumamrise webpage and display it\n",
    "summary.display_summary(summary.summarise())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
